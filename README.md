# ğŸƒâ€â™‚ï¸ Multi-Camera Player Re-Identification (Liat.ai Assignment)

This project uses a player re-identification pipeline for sports videos from two camera views (broadcast and tacticam). The goal is to assign consistent player IDs across both views using detection, tracking, feature extraction, and visual matching.

---

## ğŸ“ Project Structure

```
player_reid_system/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ broadcast.mp4
â”‚   â”œâ”€â”€ tacticam.mp4
â”‚   â””â”€â”€ yolov11_weights.pt
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ detections_broadcast.csv
â”‚   â”œâ”€â”€ detections_tacticam.csv
â”‚   â”œâ”€â”€ tracks_broadcast.csv
â”‚   â”œâ”€â”€ tracks_tacticam.csv
â”‚   â”œâ”€â”€ features_broadcast.csv
â”‚   â”œâ”€â”€ features_tacticam.csv
â”‚   â”œâ”€â”€ player_mapping_final.csv
â”‚   â”œâ”€â”€ matched_dual_view.mp4
â”‚   â”œâ”€â”€ player_matches_video.mp4
â”‚   â””â”€â”€ matches_vis/
â”œâ”€â”€ detector.py
â”œâ”€â”€ tracker.py
â”œâ”€â”€ feature_extractor.py
â”œâ”€â”€ player_matcher.py
â”œâ”€â”€ match_video_generator.py
â”œâ”€â”€ annotate_videos.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository and create a virtual environment:

```bash
git clone https://github.com/siddhi-patil-06/multi-camera-player-reid-liat.git
cd player_reid_system
python -m venv venv
source venv/bin/activate  # or venv\\Scripts\\activate on Windows
```

### 2. Install dependencies:

```bash
pip install -r requirements.txt
```

### 3. Add the required files into the `data/` folder:

- `broadcast.mp4`
- `tacticam.mp4`
- `yolov11_weights.pt`

---

## ğŸš€ How to Run the Pipeline

```bash
# Step 1: Run detection using YOLOv11
python detector.py

# Step 2: Track players using DeepSORT
python tracker.py

# Step 3: Extract RGB/size features per player
python feature_extractor.py

# Step 4: Match player IDs across views using cosine similarity
python player_matcher.py

# Step 5: Generate dual-view annotated output video
python match_video_generator.py
```

---

## ğŸ§  Methodology

- **Detection**: YOLOv11 trained to detect players and the ball.
- **Tracking**: DeepSORT (with MobileNet) assigns consistent track IDs per player.
- **Feature Extraction**: Mean color (RGB), width, height, and track duration.
- **Matching**: Cosine similarity with duration filtering and one-to-one greedy matching.
- **Visualization**: Combined output with `BID` and `TID` visual mapping.

---

## ğŸ“¦ Dependencies

Installed via `requirements.txt`. Includes:

- `ultralytics`
- `deep-sort-realtime`
- `opencv-python`
- `torch`, `torchvision`
- `numpy`, `pandas`, `scikit-learn`
- `matplotlib`, `tqdm`

---

## ğŸ“¤ Outputs

| Output File | Description |
|-------------|-------------|
| `detections_*.csv` | YOLOv11 detections per frame |
| `tracks_*.csv` | DeepSORT-tracked player IDs |
| `features_*.csv` | Extracted per-player feature vectors |
| `player_mapping_final.csv` | Final matched IDs between views |
| `matched_dual_view.mp4` | Combined view showing tracked players |
| `matches_vis/` | Cropped comparisons of matched players |

---

## ğŸ“ Notes

- Tracks with fewer than **30 frames** are excluded as noise.
- Matching ensures unique best-match IDs per view.
- You can modify the similarity threshold in `player_matcher.py`.

---

## ğŸ‘¤ Author

**Siddhi Patil**  
ğŸ“§ siddhipatil064@gmail.com  
ğŸ”— GitHub: [@siddhi-patil-06](https://github.com/siddhi-patil-06)

---

## âœ… Final Thoughts

This solution is designed to be modular, interpretable, and adaptable to real-world multi-view sports footage. Despite camera variation and occlusion, the pipeline achieves consistent cross-camera player re-identification through interpretable and scalable methods.
